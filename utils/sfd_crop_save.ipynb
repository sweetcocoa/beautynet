{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "import glob\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep_fit/\")\n",
    "sys.path.append(\"../../deep_fit/SFD_pytorch/\")\n",
    "# sys.path.append(\"../../deep_fit/utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.sfd as sfd\n",
    "import fan.face_alignment as face_alignment\n",
    "import image_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfdnet = sfd.s3fd_create_net(\"../../deep_fit/weights/s3fd_convert.pth\")\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False, enable_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = glob.glob(os.path.join('../datasets/ImageFolder/', \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in tqdm(range(0, len(image_list), batch_size)):\n",
    "    From = i\n",
    "    To = min(i+batch_size, len(image_list))\n",
    "    images_batch = []\n",
    "    for img_path in image_list[From:To]:\n",
    "        images_batch.append(io.imread(img_path))\n",
    "    boxes_batch = sfd.s3fd_detect(sfdnet, images_batch)\n",
    "\n",
    "    img_crops = None    ## crop된 이미지 배치\n",
    "    \n",
    "    for i in range(len(images_batch)):\n",
    "        center, scale = image_preprocess.get_center_scale_from_rectangle(boxes_batch[i])\n",
    "        img_crop = image_preprocess.crop(images_batch[i], center, scale, resolution=256)\n",
    "        if img_crops is None:\n",
    "            img_crops = img_crop.transpose(2, 0, 1)[np.newaxis, ]\n",
    "        else:\n",
    "            img_crops = np.concatenate([img_crops, img_crop.transpose(2,0,1)[np.newaxis, ]], axis=0)\n",
    "            #         np.save(image_list[From + i] + \"crop256\", img_crop)\n",
    "\n",
    "    img_torch  =torch.from_numpy(img_crops).float().div(255.0)\n",
    "    img_var = Variable(img_torch, volatile=True).cuda()\n",
    "    heatmap = fa.face_alignemnt_net(img_var)[-1].data.cpu().numpy()\n",
    "    for i in range(len(images_batch)):\n",
    "        pass\n",
    "#         np.save(image_list[From+i] + \"heatmap\", heatmap[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.from_numpy(img_crop.transpose((2, 0, 1))).float().div(255.0).unsqueeze_(0)\n",
    "inp = Variable(inp, volatile=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fa.face_alignemnt_net(inp)[-1].data.cpu()\n",
    "io.imshow(img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageEnhance, Image\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomEnhanceBrightness(img):\n",
    "    # factor = random.uniform(0.5, 1.5)\n",
    "    factor = random.gauss(1, 0.2)\n",
    "    factor = np.clip(factor, 0.7, 1.3)\n",
    "    return ImageEnhance.Brightness(img).enhance(factor)\n",
    "\n",
    "\n",
    "def RandomEnhanceColor(img):\n",
    "    factor = random.gauss(1, 0.2)\n",
    "    factor = np.clip(factor, 0., 1.5)\n",
    "    return ImageEnhance.Color(img).enhance(factor)\n",
    "\n",
    "\n",
    "def RandomEnhanceContrast(img):\n",
    "    factor = random.gauss(1, 0.2)\n",
    "    factor = np.clip(factor, 0.8, 2)\n",
    "    return ImageEnhance.Contrast(img).enhance(factor)\n",
    "\n",
    "\n",
    "def RandomEnhanceSharpness(img):\n",
    "    factor = random.gauss(1, 0.3)\n",
    "    factor = np.clip(factor, -1, 5)\n",
    "    return ImageEnhance.Sharpness(img).enhance(factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Compose([\n",
    "        Image.fromarray,\n",
    "        RandomEnhanceBrightness,\n",
    "        RandomEnhanceColor,\n",
    "        RandomEnhanceContrast,\n",
    "        RandomEnhanceSharpness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pimage = Image.fromarray(img_crop)\n",
    "pimage = ImageEnhance.Brightness(pimage).enhance(0.5)\n",
    "pimage = ImageEnhance.Color(pimage).enhance(1.5)\n",
    "pimage = ImageEnhance.Contrast(pimage).enhance(1.2)\n",
    "pimage = ImageEnhance.Sharpness(pimage).enhance(0.5)\n",
    "pimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr(img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = [0, 17, 22, 27, 31, 36, 42, 48, 60, 68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(out[0].sum(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt3]",
   "language": "python",
   "name": "conda-env-pt3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
